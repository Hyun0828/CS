# Virtualization

# 목차
- [Address Spaces](#13-address-spaces)
  - [초기 시스템](#초기-시스템) 
  - [멀티프로그래밍과 시분할](#멀티프로그래밍과-시분할) 
  - [주소 공간](#주소-공간) 
  - [목표](#목표)
- [Address Translation](#15-address-translation)
  - [동적 재배치](#동적-재배치)
  - [운영체제 이슈](#운영체제-이슈)
  - [정리](#정리)
- [Segmentation](#16-segmentation)
  - [세그멘테이션](#세그멘테이션)
  - [세그먼트의 종류](#세그먼트의-종류)
  - [스택](#스택)
  - [공유 지원](#공유-지원)
  - [소단위와 대단위](#소단위와-대단위)
  - [운영체제의 지원](#운영체제의-지원)
- [Free Space Management](#17-free-space-management)
  - [저수준 기법](#저수준-기법)
  - [빈 공간 할당 전략](#빈-공간-할당-전략)
- [Introduction to Paging](#18-introduction-to-paging)
  - [페이지 테이블은 어디에 저장될까](#페이지-테이블은-어디에-저장될까)
  - [페이지 테이블의 구성](#페이지-테이블의-구성)
  - [페이징](#페이징)
- [Translation LookAside Buffer](#19-translation-lookaside-buffer)
  - [TLB의 기본 알고리즘](#tlb의-기본-알고리즘)
  - [TLB 미스는 누가 처리할까](#tlb-미스는-누가-처리할까)
  - [TLB의 구성](#tlb의-구성)
  - [문맥 교환](#문맥-교환)
  - [교체 정책](#교체-정책)
  - [실제 TLB](#실제-tlb)
- [Advanced Page Tables](#20-advanced-page-tables)
  - [더 큰 페이지](#더-큰-페이지)
  - [하이브리드 방식](#하이브리드-방식)
  - [멀티 레벨 페이지 테이블](#멀티-레벨-페이지-테이블)
  - [역 페이지 테이블](#역-페이지-테이블)
  - [스와핑](#스와핑) 

## 13. Address Spaces

### 초기 시스템

초기 컴퓨터는 많은 기능을 제공하지 않았다. 

![image](https://github.com/user-attachments/assets/0baeb71f-ba0f-4667-b4e9-50861b1f4630)

위 그림과 같이 물리 메모리에 하나의 프로세스만 존재했고 가상화는 거의 존재하지 않았다.

### 멀티프로그래밍과 시분할

시간이 지나면서 **멀티프로그래밍** 시대가 도래하였다. 운영체제는 여러 프로세스를 번갈아 가며 실행하였다. 한 프로세스가 입출력을 실행하면 CPU는 다른 프로세스로 전환하여 CPU의 이용률을 증가시켰다. 

곧 사람들은 **일괄처리방식** 컴퓨팅의 한계를 인식하고 즉시 응답을 받을 수 있는 대화식 이용 개념을 중요하게 생각하며 **시분할 컴퓨팅**의 시대가 시작되었다.

시분할을 구현하는 한 가지 방법은 하나의 프로세르를 짧은 시간 동안 실행시키는 것이다. 이후 프로세스를 중단하고 프로세스의 모든 상태를 디스크 종류의 장치에 저장하고 다른 프로세스의 상태를 탑재하여 실행시켰다. 그러나 이 방식은 레지스터 상태를 저장하고 복원하는 것에 문제는 없었지만 메모리의 내용 전체를 디스크에 저장하는 것에서 성능 상 문제가 발생했다. 

![image](https://github.com/user-attachments/assets/0ba1f673-76a8-4815-8a1c-7b348887bcef)

이런 시분할 시스템이 대중화되면서 각 **프로세스가 다른 프로세스를 접근하지 못하게 해야 하는 보호**가 중요한 문제로 대두되었다.

### 주소 공간

위와 같은 위험한 행위를 대비하기 위해 **주소 공간(Address Space)** 개념이 등장했다. 주소 공간은 실행 프로그램의 모든 메모리 상태를 갖는다. 명령어를 저장하는 **코드(code)** 와 함수 호출 체인 상의 현재 위치, 지역 변수, 함수 인자와 반환 값 등을 저장하는 **스택(stack)**, 동적으로 할당되는 메모리 공간인 **힙(heap)** 이 있다. 정적 변수를 저장하는 데이터 영역도 있다.

![image](https://github.com/user-attachments/assets/38c8c5b9-495f-44a6-a5e0-5e394463e0f5)

코드는 정적이기 때문에 주소 공간 상단에 배치하고 힙과 스택은 메모리가 확장되거나 축소될 수 있기 때문에 상단과 하단에 둔다. 힙은 아래 방향으로 확장하고 스택은 위 방향으로 확장하는데 이러한 배치는 관례일 뿐이다. **특히 멀티 쓰레드 환경에서는 이런 식으로 주소 공간을 나누면 동작하지 않는다.**

위의 그림처럼 실제로  프로그램이 물리 주소 0~16KB 사이에 존재하는 것은 아니다. 실제로는 임의의 물리 주소에 탑재된다. 그럼 그 물리 주소는 어떻게 알 수 있을까? 이 개념이 바로 메모리 가상화이다. 왜냐하면 프로그램은 자신이 특정 주소의 메모리에 탑재되고 큰 주소 공간을 가지고 있다고 생각하지만 현실은 그렇지 않기 때문이다.

### 목표

가상 메모리 시스템(VM)의 주요 목표는 다음과 같다.

- 투명성(transparency) : 운영체제는 실행 중인 프로그램이 가상 메모리의 존재를 인지하지 못하도록 구현해야 한다. 프로그램이 물리 메모리를 소유한 것처럼 행동하게 만들고 운영체제와 하드웨어가 모든 작업을 처리한다.
- 효율성(efficiency) : 시간적으로 너무 느려서는 안 되며 공간적으로는 너무 많은 메모리를 사용해선 안 된다.
- 보호(protection) : 운영체제는 서로 다른 프로세스끼리 영향을 주게 만들어선 안 되며 프로세스가 운영체제의 코드에 접근하게 만들어선 안 된다.

여담으로 예전에 c/c++ 수업에서 포인터를 이용해 변수의 주소를 출력해본 적이 있다. 이 때는 각 주소가 실제 메모리 주소 값 인줄 알았는데 사실 해당 주소는 가상 주소라고 한다. 이것이 바로 프로세스가 가상 메모리의 존재를 인지하지 못하게 하는 가상화 기술의 핵심이다.

## 15. Address Translation

가상 주소를 물리 주소로 바꾸는 주소 변환, 즉 메모리 가상화를 위한 첫 번째 시도를 살펴보자. 우선 사용자의 주소 공간은 물리 메모리에 연속적으로 배치되어야 한다고 가정한다. 또한 각 주소 공간의 크기는 같다고 가정한다. 물론 이후에는 이 가정을 완화하여 실제 메모리 가상화 기법을 배울 것이다.

프로그램 관점에서 주소 공간의 크기가 16KB라고 해보자. 프로그램의 모든 메모리 참조는 이 범위 내에 있어야 한다. 메모리 가상화를 위해서 운영체제는 프로세스를 물리 메모리 주소 0이 아닌 다른 곳에 위치시키고 싶다. 어떻게 프로세스 모르게 메모리를 다른 위치에 재배치 할 수 있을까?

### 동적 재배치

최초 시분할 컴퓨터에서는 베이스와 바운드라는 아이디어가 채택되었다. 이 기술은 동적 재배치라고 한다.

각 CPU마다 **base 레지스터** 와 **bound 레지스터** 가 존재한다. 베이스와 바운드 쌍은 우리가 원하는 위치에 주소 공간을 배치할 수 있게 한다. 배치와 동시에 프로세스가 오직 자신의 주소 공간에만 접근하는 것을 보장한다. 운영체제가 프로그램을 물리 메모리에 적재할 때 그 위치를 베이스 레지스터에 저장한다. 만약 프로세스가 물리주소 32KB에 저장된다면 베이스 레지스터에는 32KB가 저장된다.

```makefile
physical address = virtual address + base
```

위와 같이 주소 변환이 이루어진다.

예를 들어 PC 값이 128이고 베이스 레지스터 값이 32KB면 실제로 접근하는 물리주소는 32896이다. 만약 가상 주소 15KB의 값을 가져오라는 명령어를 실행하면 물리주소 47KB에 접근하는 것이다. 프로세스가 실행을 시작한 이후에도 주소 공간을 이동할 수 있기 때문에 동적 재배치라고 부른다.

바운드 레지스터는 프로세스 보호에 사용된다. 이 때 바운드 레지스터는 2가지 방식으로 정의될 수 있다.

- 바운드 레지스터에 주소 공간의 크기를 저장하고 접근하려는 가상 주소 값이 바운드 레지스터 값보다 크면 예외가 발생한다.
- 바운드 레지스터에 주소 공간의 마지막 물리 주소를 저장하고 실제로 변환한 물리 주소 값이 바운드 레지스터 값보다 크면 다른 프로세스를 접근하는 것이므로 예외가 발생한다.

### 운영체제 이슈

베이스, 바운드 방식의 가상 메모리 구현을 위해서 운영체제가 개입되어야 하는 시점들이 존재한다.

첫째, 프로세스가 생성될 때 운영체제는 주소 공간이 저장될 메모리 공간을 찾아야 한다. 다행히 주소 공간의 크기가 일정하고 물리 메모리를 슬롯의 배열로 보아 각 슬롯의 사용 여부를 관리한다. 운영체제는 새로운 프로세스를 할당할 공간을 찾기 위해 빈 리스트(free list)라는 자료구조를 검색한다.

둘째, 프로세스가 종료할 때 프로세스가 사용하던 메모리 공간을 빈 리스트에 넣고 정리한다.

셋째, 운영체제는 문맥 교환이 발생할 때 PCB에 베이스와 바운드 레지스터 값을 저장해야 한다. 마찬가지로 새로운 프로세스를 실행할 때 PCB에서 베이스와 바운드 레지스터 값을 로드해야 한다.

운영체제가 주소 공간의 위치를 쉽게 옮길 수 있는데 프로세스의 실행을 중지시키고 새 위치로 주소 공간을 복사한다. 그리고 베이스 레지스터 값을 갱신하여 새 위치를 가리키게 한다.

넷째, 운영체제는 부팅할 때 예외 핸들러 또는 호출될 함수를 제공해야 한다. 예를 들어, 프로세스가 바운드 레지스터 값 밖의 메모리 공간에 접근하려는 경우 CPU는 예외를 발생시킨다. 운영체제는 이러한 예외가 발생할 때 조치를 취할 준비가 되어 있어야 한다.

### 정리

동적 재배치 방식은 베이스 레지스터를 가상 주소에 더하고 생성된 주소가 바운드 레지스터를 벗어나는지 검사하는 하드웨어 회로만 추가하면 되기 때문에 간단하고 매우 효율적이다. 또한 프로세스 보호 기능도 제공한다. 그러나 동적 재배치는 비효율적이기도 하다. 

<img src="https://github.com/user-attachments/assets/457bc4b9-b553-4ffb-8588-ae6d92de9dfb" width="200"/>

위와 같이 32KB에서 42KB의 물리 메모리를 사용할 때, 스택과 힙이 크지 않아 둘 사이의 공간이 낭비되는데 이를 내부 단편화라고 한다. 고정 크기 슬롯에 주소 공간을 배치해야 하기 때문에 내부 단편화를 필연적이다. 이를 방지하기 위해 더 정교한 기법이 필요하다. 그러한 기법을 세그멘테이션이라고 부른다.

## 16. Segmentation

동적 재배치 방식의 문제점은 메모리 낭비가 심하다는 것이다. 모든 주소 공간을 메모리에 적재하다 보니 힙과 스택 사이에 사용하지 않는 공간처럼 메모리 낭비가 발생하게 된다. 그래서 이 문제를 해결하기 위해 **세그멘테이션(segmentation)** 기법이 등장했다.

### 세그멘테이션

기존에는 주소 공간마다 베이스와 바운드 레지스터가 존재했다. 특정 길이를 가지는 연속적인 주소 공간인 세그먼트마다 베이스와 바운드 쌍을 두고 각 세그먼트를 물리 메모리의 각기 다른 위치에 배치할 수 있으며 사용되지 않는 세그먼트는 물리 메모리에 올리지 않아 메모리 낭비를 방지할 수 있다.

<img src="https://github.com/user-attachments/assets/b0b8ce7e-cb57-49d1-987b-c1cc23b00d72" height="400" width="200"/>
<img src="https://github.com/user-attachments/assets/90bdee0b-549d-4a07-a32b-dcf535b00679" width="200"/>

스택, 코드, 힙 3개의 세그먼트를 독립적으로 배치한다. 

가상 주소 100번지를 참조한다고 하자. 100번지는 주소 공간에서 코드 세그먼트에 속한다. 코드 세그먼트의 베이스 값에 100번지를 더해 32KB+100이 물리 주소가 된다. 이 때 바운드 레지스터는 각 세그먼트의 크기를 저장한다. 100번지인 offset이 바운드보다 작으면 된다.

만약 4200번지를 참조한다고 해보자. 4200번지는 힙 세그먼트에 속한다. 물리 주소를 계산할 때 주의할 점은 4200번지에 34KB를 더하는 것이 아니라 힙 안에서의 offset을 더해주어야 한다. offset은 4200-4KB이므로 104이다. 물리 주소는 104 + 34KB가 된다.

만약 힙을 벗어나 7KB번지를 참조한다고 하자. 하드웨어가 그 주소가 범위를 벗어났다는 것을 감지하고 **Segmentation Fault** 를 발생시킨다.

### 세그먼트의 종류

하드웨어는 가상 주소가 어느 세그먼트를 참조하는 지 어떻게 알 수 있을까? 가상 주소의 최상위 몇 비트를 기준으로 세그먼트를 구분한다. 예를 들어 힙, 스택, 코드 3개의 세그먼트를 구분하기 위해서 최상위 2비트를 세그먼트 구분에 사용한다.

<img src="https://github.com/user-attachments/assets/1384e8d3-5705-45a2-87cc-b307156f2bdd" width="250"/>

<img src="https://github.com/user-attachments/assets/eba3663f-b387-4218-b255-e790f6524284" width="250"/>

00이면 코드, 01이면 힙, 10이면 스택 등으로 구분한다. 예를 들어 4200번지를 변환해보자.

4200번지는 위와 같은데 세그먼트 비트가 01이니 힙 영역이고 오프셋은 나머지 12비트인 104이다. 오프셋 값이 바운드보다 작은 지 여부도 추가로 검사해주면 된다. 그런데 최상위 2비트를 사용하면 지정 가능한 하나의 세그먼트는 미사용으로 남아 전체 주소 공간의 1/4은 사용이 불가능하다. 이 문제를 위해 힙과 코드를 하나의 세그먼트로 합치고 최상위 1비트만 사용하는 경우도 있다.

### 스택

스택은 다른 세그먼트와 달리 반대 방향으로 확장된다. 따라서 다른 방식의 변환이 필요하다. 이를 위해 하드웨어는 세그먼트가 어느 방향으로 확장하는 지에 대한 비트를 저장한다. 1이면 주소가 커지는 쪽으로, 0이면 주소가 작아지는 쪽으로 확장한다. 

<img src="https://github.com/user-attachments/assets/433168c8-e6f1-4061-9603-a431110f1495" width="300"/>

예를 들어 가상 주소 15KB에 접근한다고 하자. 15KB는 11 1100 0000 0000 이므로 상위 2비트를 제외하면 3KB의 오프셋이 남는다. 다른 세그먼트는 이 오프셋을 그대로 활용하지만 스택은 오프셋에서 세그먼트 크기를 뺀 -1KB를 오프셋으로 사용한다. 따라서 물리 주소는 베이스 28KB - 1KB = 27KB가 된다.

### 공유 지원

메모리를 절약하기 위해 주소 공간들 간에 특정 세그먼트를 공유하기도 하는데 **코드 공유가 일반적이다.**

공유를 지원하기 위해 **protection bit** 추가가 필요하다. 세그먼트를 읽을 수 있는지 쓸 수 있는지를 결정하는 비트이다. 코드 세그먼트를 읽기 전용으로 설정하면 주소 공간의 독립성을 유지하면서도 여러 프로세스가 주소 공간을 일부 공유할 수 있다. 

<img src="https://github.com/user-attachments/assets/c7ee49f2-4851-464b-8e28-bedf8297e9a5" width="350"/>

### 소단위와 대단위

지금까지 코드, 스택, 힙 같은 소수의 세그먼트만 지원하는 시스템만 보았다. 비교적 큰 단위의 공간으로 분할하는 **대단위(coarse-grained)** 라고 한다. 더 작은 크기의 공간으로 나누는 것을 **소단위(fined-grained)** 세그멘테이션이라고 부른다. 많은 수의 세그먼트를 지원하기 위해 세그먼트 테이블을 이용해 손쉽게 생성하고 융통성 있게 관리할 수 있다.

### 운영체제의 지원

세그먼트를 독립적으로 물리 메모리에 배치하기 때문에 물리 메모리를 엄청나게 절약할 수 있다. 그러나 세그멘테이션도 많은 문제를 제기한다.

- 문맥 교환시 세그먼트 레지스터의 저장과 복원 과정이 추가로 필요하다.
- 미사용 중인 물리 메모리 공간의 관리가 필요하다.
- 가장 큰 문제는 **외부 단편화(external fragmentation)** 로 인한 메모리 낭비다.

    <img src="https://github.com/user-attachments/assets/4da3295f-6ec3-4484-8ff8-c0fdb77b2c09" width="400"/>

세그먼트의 크기가 달라 위와 같은 상황이 발생한다. 분명 빈 공간의 총합은 크지만 새로운 세그먼트를 물리 메모리에 배치하지 못한다. 이 문제의 해결책 중 하나로 **압축** 이 있다. 그러나 압축은 비용이 많이 드는 문제가 있다. 

다른 간단한 방법은 빈 공간 리스트를 관리하는 알고리즘을 사용하는 것인데 최적 적합(best-fit), 최악 적합(worst-fit), 최초 적합(first-fit) 및 버디 알고리즘(buddy algorithm) 등을 포함해 수백 개의 방식이 존재한다. **그러나 알고리즘이 아무리 정교하게 동작해도 세그멘테이션에선 외부 단편화를 막을 수 없다.**

## 17. Free Space Management

페이징 개념을 사용하기 전에 세그멘테이션으로 물리 메모리를 관리할 때 빈 공간 관리는 어려운 문제다. 빈 공간 관리를 효율적으로 하는 방법들에 대해 알아보자.

void malloc(size_t size)와 void free(void *ptr)과 같은 기본 인터페이스를 가정한다. 이 라이브러리가 관리하는 공간인 힙의 빈 공간을 관리하는 데는 일반적으로 연결리스트가 사용된다. 물론 반드시 리스트일 필요는 없다.

### 저수준 기법

우선 대부분의 할당기에서 사용하는 분할과 병합에 대해 알아보자. 두 번째로 할당된 영역의 크기를 빠르고 상대적으로 쉽게 파악할 수 있는 방법을, 마지막으로 빈 공간과 사용 중인 공간을 추적하기 위해 간단한 리스트를 구현하는 방법을 살펴보자.

1. **분할과 병합**
    
    빈 공간 리스트는 힙에 있는 빈 공간들의 집합이다.
   
    <img width="302" alt="image" src="https://github.com/user-attachments/assets/60da3c42-d401-4c44-ab4f-0e05965c59e0" />
    <img width="374" alt="image" src="https://github.com/user-attachments/assets/704a2272-5407-4ad1-bf20-88d913b7daab" />
    
    위와 같이 10바이트짜리 빈 공간이 2개 있다고 가정하면 빈 공간 리스트는 위와 같다. 이런 상황에선 외부 단편화 문제로 인해 10바이트를 초과하는 모든 요청은 NULL을 반환할 것이다. 그럼 10바이트보다 작은 요청은 어떻게 처리할까?
    
    1바이트 요청이 발생했다고 하면 **분할**이 수행된다. 할당기가 리스트의 두 번째 원소를 사용해 빈 공간을 할당해주었다고 하면 아래와 같이 변한다.
   
    <img width="360" alt="image (2)" src="https://github.com/user-attachments/assets/78be6515-d4bd-421a-a3b8-3a741dec7dd8" />
    
    만약 free(10)을 통해 메모리를 반환하게 되면 리스트는 어떻게 변할까? 단순히 노드를 추가해보자..
    <img width="489" alt="image (3)" src="https://github.com/user-attachments/assets/90288d8f-f8dc-486d-b354-ea9c1eb91407" />
    
    여기서 외부 단편화 문제가 발생한다. 빈 공간의 총합은 30바이트 이지만 10바이트를 초과하는 요청에 대해서는 메모리 할당이 불가능해진다. 그래서 **메모리 청크의 주소와 인접한 빈 청크를 병합하는 과정**을 거친다.

    <img width="241" alt="image (4)" src="https://github.com/user-attachments/assets/ac682062-5c94-4c29-8254-170afb129a87" />
    
3. **할당된 공간의 크기 파악**
    
    free 메소드는 메모리 영역의 주소만 인자로 넘겨줄 뿐, 해제되는 메모리 영역의 크기는 모른다. 이 정보를 어떻게 알 수 있을까?
    
    이 작업을 위해 대부분의 할당기는 **메모리 앞에 헤더 블럭에 추가 정보를 저장한다.**
   
    <img width="478" alt="image (5)" src="https://github.com/user-attachments/assets/198a7b6e-b084-497a-a674-ed387fc66b7a" />
    
    ptr = malloc(20);을 호출해도 20바이트 메모리 공간 앞에 기타 정보를 저장한다. 이 때 magic 값은 부가적인 무결성 검사를 제공하기 위한 매직 넘버이다.
    
    헤더 공간의 추가적인 할당을 위해 사용자가 N 바이트를 요청해도 사실은 N + 헤더 크기 만큼의 청크를 빈 공간 리스트에서 탐색하게 된다.
    
5. **빈 공간 리스트 내장**
    
    이러한 빈 공간 리스트를 빈 공간에 어떻게 구현할 수 있을까?

    <img width="515" alt="image (6)" src="https://github.com/user-attachments/assets/0274dc1c-44eb-46b6-952c-3336833470bd" />
    
    힙의 크기가 4KB라고 가정하자. 첫 빈 공간 리스트는 위와 같이 생성된다. 여기서 만약 100 바이트 공간 할당 요청이 발생했다고 하면 어떻게 될까? 헤더 크기를 8바이트라고 가정하면 108바이트 공간이 청크에서 분할된다. 4088 - 108 = 3980 바이트의 빈 공간 청크가 남는다.

    <img width="513" alt="image (7)" src="https://github.com/user-attachments/assets/da539f7d-8db7-46fe-9d13-eec5ec75c5cb" />
    
     만약 100바이트씩 할당된 공간이 3개라고 해보자. (2번의 추가적인 요청)

    <img width="518" alt="image (8)" src="https://github.com/user-attachments/assets/b61a0fea-fb4c-4a5f-b291-5b9a34f27686" />
    
    위 상황에서 free(16500)을 호출하면 어떻게 될까? 16500은 16384 + 108 + 8로 위 그림에서 sptr의 위치와 같다.
   
    <img width="530" alt="스크린샷 2025-04-20 오후 12 41 18" src="https://github.com/user-attachments/assets/48f93597-5cfd-45f1-bfc8-22a2c98efe89" />

    간단하다. 헤더의 내용만 size와 다음 빈 공간 청크를 가리키는 next 주소값으로 변경된다. 나머지 공간들도 해제된다면 같은 방식으로 빈 공간 리스트가 형성되지만 청크들이 단편화되어 있는 문제가 있다. 이는 인접 청크끼리 병합하여 해결할 수 있다.
    
7. **힙의 확장**
    
    만약 힙 전체 공간이 부족하면 어떻게 해야 할까? 가장 쉬운 방법은 실패를 반환하는, 즉 NULL 값을 반환하는 것이다. 물론 이 방법도 좋긴 하지만 특정 시스템 콜 (UNIX에서는 sbrk)을 통해 빈 물리 공간에서 새로운 청크를 할당 받을 수 있다. 
    

### 빈 공간 할당 전략

빈 공간 리스트가 어떻게 생겼는지 알았으니 요청이 발생했을 때 어떤 청크가 할당 되어야 할 지를 알아보자. 결국 이상적인 할당기는 빠르고 단편화를 최소로 만들어야 한다. 

1. **최적 적합 (Best Fit)**
    
    빈 공간 리스트를 검색하여 요청한 크기와 같거나 더 큰 메모리 청크 중 가장 작은 크기의 청크를 반환한다. 매우 간단하지만 Worst-Case에서 모든 청크를 탐색해야 한다.
    
2. 최악 적합 (Worst Fit)
    
    가장 큰 빈 청크를 찾아 분할하게 되는데 이 역시 빈 공간 전체를 탐색해야 하기 때문에, 또한 단편화가 많이 발생하는 문제가 있다.
    
3. **최초 적합 (First Fit)**
    
    간단하게 요청보다 큰 첫 블럭을 찾아서 요청만큼 반환한다. 속도가 빠르긴 하지만 리스트의 시작 부분에 단편화된 작은 청크들이 많이 몰리게 된다. 따라서 빈 공간 리스트를 주소-기반 정렬시켜 어느정도 해소할 수 있다.
    
4. **다음 적합 (Next Fit)**
    
    최초 적합과 달리 첫 탐색 이후의 탐색에 대해서 이전 탐색에서 찾았던 청크 이후부터 탐색하여 리스트의 첫 부분에만 단편이 집중적으로 발생하는 문제를 해소한다. 성능은 최초 적합과 비슷하다.
    

간단하게 예를 들어 보자.

빈 공간 리스트가 “10 → 30 → 20” 이라고 해보자. 그리고 15바이트 요청이 발생했다고 하면

- 최적 적합 : 10 → 30 → 5
- 최악 적합 : 10 → 15 → 20
- 최초 적합 : 10 → 15 → 20
- 다음 적합 : 10 → 15 → 20

이 기본적인 접근 방식 외에도 다른 방법들도 있다. 

5. **개별 리스트(Segregated List)**
    
    특정 응용 프로그램이 한두 개 자주 요청하는 크기가 있다면, 그 크기의 객체를 관리하기 위한 별도의 리스트를 유지한다. 예를 들어 2KB 요청이 자주 발생한다면 2KB 크기들의 메모리 청크를 따로 관리하여 할당과 해제 요청을 신속하게 처리하는 것이다. 이 문제는 특정 메모리 풀과 일반 메모리 풀의 메모리 할당 비율 문제가 있다.
    

6. **슬랩 할당기(Slab Allocator)**
    
    커널이 부팅될 때, 커널 객체를 위한 여러 객체 캐시를 할당한다. 커널 객체란 락, 아이노드 등 자주 요청되는 자료 구조이며 객체 캐시는 지정된 크기의 객체들로 구성된 빈 공간 리스트이다. 개별 리스트 방식에 비해 사전에 빈 객체들을 초기화된 상태로 유지하기 때문에 성능이 더 우수하다.
    
7. **버디 할당(Buddy Allocator)**

    <img width="309" alt="image (9)" src="https://github.com/user-attachments/assets/ea5141bf-3e01-452c-8df3-415cdf27f6e2" />
    
    빈 메모리는 개념적으로 2^N인 하나의 큰 공간으로 생각된다. 메모리 요청이 발생하면 요청을 충족시키기에 충분한 공간이 생길 때까지 빈 공간을 2개로 분할한다. 예를 들어 7KB 요청이 발생하면 8KB가 등장할 때까지 2개씩 분할한다. 메모리 크기가 2의 거듭제곱 형태이기 때문에 내부 단편화 문제가 빈번하게 발생한다. 그러나 블럭이 해제될 때, 블럭끼리 합병하는 과정이 쉬우며 트리를 따라 합병이 가능할 때까지 계속 진행된다.


## 18. Introduction to Paging

보통 공간 관리 문제는 세그멘테이션이나 페이징 방식으로 해결한다. 세그멘테이션은 단편화 문제로 인해 동일 크기의 조각인 페이지로 주소 공간을 분할하는 **페이징** 방식이 많이 사용된다. 그에 상응하여 물리 메모리도 페이지 프레임이라고 불리는 고정 크기의 슬롯으로 나눈다.

<img width="317" alt="image (2)" src="https://github.com/user-attachments/assets/bb0c7425-5566-486d-9597-48c2ec9cd368" />
<img width="393" alt="image" src="https://github.com/user-attachments/assets/316a756c-00ef-411a-ad24-d44dfe34a835" />

주소공간을 64KB, 페이지를 16KB, 물리 메모리를 128KB라고 가정하자.

커널 영역을 제외하고 ‘페이지3-프레임2’ 와 같이 페이지와 프레임은 1대1로 대응된다. 페이지에 대한 프레임 위치를 기록하기 위해 운영체제는 **페이지 테이블(page table)** 이라는 자료구조를 사용한다. 페이지 테이블의 역할은 가상 주소를 물리 주소로 변환하는 것이다. 그래서 이러한 페이지 테이블은 프로세스 마다 존재하는데 역 페이지 테이블처럼 예외적인 기법도 있다.

가상 주소 변환을 위해서 가상 주소를 **가상 페이지 번호(virtual page number, VPN)과 오프셋**으로 구분해야 한다. 예를 들어 가상 주소 공간의 크기가 64바이트이면 가상 주소는 6비트이다. 이 때 페이지 크기가 16바이트라면 최상위 2비트가 VPN, 하위 4비트가 오프셋이 된다.

예를 들어 보자, 가상 주소 21은 이진수로 010101이다. 이 때 01이 VPN이고 0101이 Offset이 된다.

<img width="399" alt="image (1)" src="https://github.com/user-attachments/assets/315dc32d-55fc-42bf-9734-e5f5c0abb9f6" />

페이지 테이블에서 해당 VPN에 대한 PFN을 찾아 바꿔주기만 하면 주소 변환은 끝이다.

### 페이지 테이블은 어디에 저장될까

32비트 운영체제에선 가상 주소가 32비트이다. 페이지 크기가 4KB일 때 VPN은 20비트, 오프셋은 12비트인데 이 말은 페이지 개수가 2^20개라는 것이다. **페이지 테이블 항목(page table entry, PTE)** 가 4바이트라고 가정해도 프로세스 1개당 페이지 테이블의 크기는 4MB이다. 만약 프로세스가 100개면 400MB의 물리 메모리 공간을 차지하게 된다. 64비트 운영체제에선 이보다 훨씬 큰 숫자다.

페이지 테이블은 가상 메모리나 디스크에 스왑될 수 있지만 아직은 물리 메모리에 존재한다고 생각하자.

### 페이지 테이블의 구성

페이지 테이블은 어떤 자료구조로도 구현이 가능하지만 우선 선형 페이지 테이블 형태인 배열을 쓴다고 가정하자. 그럼 각 PTE는 어떻게 구성되어 있을까?

- Valid Bit : 주소 공간이 프레임에 할당되어 있는지 아닌지를 표기한다.
- Protection Bit : 페이지에 대한 읽기, 쓰기, 실행 권한을 설정한다.
- Present Bit : 페이지가 메모리에 적재되어 있는지를 표기한다. (Valid Bit와 거의 동일하다고..한다)
- Dirty Bit : 페이지가 적재 후 변경되었는지 여부를 표기한다.
- Reference Bit : 페이지가 참조된 적이 있는지 표기한다. 후에 페이지 교체 알고리즘에서 사용된다.

그 외에 여러 비트들이 있으나..  그다지 중요하진 않은 듯 하다.

### 페이징

페이지 테이블이 메모리에 존재하기 때문에 명령어를 실행할 때 **속도 저하**가 발생한다. 예를 들어 주소 21에 대한 참조를 진행한다고 하면 1️⃣ 페이지 테이블에 접근해 가상 주소 21을 변환한다. 2️⃣ 물리 주소를 이용해 메모리에 접근한다. 이 과정을 위해서는 페이지 테이블의 위치를 우선 알아야 하는데 보통 **페이지 테이블 베이스 레지스터(PTBR)** 에 저장되어 있다.

```c
VPN = (VirtualAddress & VPN_MASK) >> SHIFT
PTEAddr = PTBR + (VPN * sizeof(PTE))
PTE = AccessMemory(PTEAddr)

if (PTE.Valid == False)
  RaiseException(SEGMENTATION_FAULT)
else if (CanAccess(PTE.ProtectBits) == False)
  RaiseException(PROTECTION_FAULT)
else
  offset = VirtualAddress & OFFSET_MASK
	PhysAddr = (PTE.PFN << PFN_SHIFT) | offset
	Register = AccessMemory(PhysAddr)
```

명령어 1개가 실행될 때, 명령어의 위치를 알기 위해서 페이지 테이블을 접근하고 실제 명령어를 실행하기 위해 메모리에 접근하면서 적어도 2번의 메모리 접근이 발생한다. 명령어를 실행할 때 변수를 사용하는 것처럼 특정 위치에 추가 접근이 필요하면 메모리 접근 횟수가 더 늘어날 것이다. 또한 프로세스 개수가 증가하면서 메모리에 적재되는 페이지 테이블 용량이 기하급수적으로 늘어난다. 이 2가지 문제를 어떻게 해결할 수 있을까?

## 19. Translation LookAside Buffer

앞서 말했지만 페이징은 성능 저하가 발생하게 된다. 그럼 주소 변환을 어떻게 빠르게 처리할 수 있을까? 우리는 TLB라고 하는 MMU의 일부인 주소-변환 캐시를 사용한다. 

### TLB의 기본 알고리즘

1. 가상 주소에서 VPN을 추출하고 TLB의 존재 여부를 검사한다.
2. TLB 히트면 주소를 변환해 접근한다.
3. TLB 미스면 페이지 테이블에 접근해 변환 후 TLB를 갱신하고 명령어를 재실행한다.

따라서 우리는 일반적인 캐시처럼 TLB 미스를 줄이는 방안을 생각해야 한다.

간단한 배열 접근 예제를 통해 알아보자.

<img width="247" alt="image" src="https://github.com/user-attachments/assets/1ec8a67d-9236-408b-82c9-c8d3b1e537d2" />

가상 주소는 8비트, 페이지 크기는 16바이트라고 하자. VPN이 4비트, 오프셋이 4비트가 된다. 위 그림을 보면 주소 공간이 16개의 페이지로 구성되어 있다. 

```c
int sum = 0;
for(int i=0; i<10; i++)
	sum += arr[i];
```

이런 간단한 코드를 실행할 때, 정수 배열에 대한 매모리 접근을 살펴보자. 정수는 4바이트이기 때문에 하나의 페이지에는 4개의 배열 항목이 저장될 수 있다. 처음 a[0]에 접근할 때는 TLB Miss일테고 TLB에 VPN=06에 대한 정보가 갱신된다. 그럼 이후 a[1], a[2]는 TLB Hit가 발생한다. 똑같이 a[3], a[7]은 TLB Miss이며 나머지는 TLB Hit로 TLB Git율이 70%나 된다. 이렇게 배열 접근은 보통 공간 지역성을 통해 히트율을 높이게 된다.

이 때 TLB Hit 비율을 높이기 위해서 **페이지 크기를 크게 만들 수 있다**. 만약 페이지 크기가 두 배가 되면 페이지 1개에 배열 원소를 8개나 저장할 수 있다. 만약 for문이 종료된 이후에 배월에 접근한다면 이미 배열의 주소 변환 정보가 TLB에 갱신되어 있으니 시간 지역성으로 인해 TLB의 히트율이 높아진다.

### TLB 미스는 누가 처리할까

TLB 미스는 누가 처리할까? CPU의 종류에 따라 달라진다. 과거에는 CISC라는 복잡한 명령어들로 구성된 CPU를 사용했다. **CISC CPU에서는 TLB Miss를 하드웨어가 처리하도록 설계했다.** 보편적으로 알고 있는 TLB Miss 알고리즘인데 어떻게 처리되는 지 보자

1. TLB Miss 발생 시 PTBR을 통해 페이지 테이블에 접근해 PTE를 찾는다.
2. 변환 정보를 추출해 TLB를 갱신한다.
3. 명령어를 재실행한다.

반면에 최근에 등장한 컴퓨터 구조인 **RISC 기반 CPU에서는 TLB Miss를 소프트웨어인 운영체제가 처리한다.** 

1. TLB Miss 발생 시 하드웨어는 exception 시그널을 발생시킨다.
2. 운영체제는 명령어 실행을 중지하고 실행 모드를 커널 모드로 변경한다.
3. 트랩 핸들러를 실행하고, 핸들러가 페이지 테이블을 검색하여 정보를 추출해 TLB를 갱신한다.
4. 트랩 핸들러에서 리턴되면 명령어를 재실행한다.

초반에 트랩에 대해 공부할 때, 트랩 핸들러에서 리턴되면 다음 명령어를 실행한다고 했는데 여기선 해당 명령어를 재실행한다. **트랩 발생 원인에 따라 현재 명령어의 PC 값 혹은 다음 명령어의 PC 값을 달리 저장하는 것이다.** 

또한 TLB Miss 핸들러를 실행할 때, TLB Miss가 무한 반복되지 않게 주의해야 한다. 이를 위해 핸들러를 물리 메모리에 위치 시켜 주소 변환을 필요없게 만들거나 TLB의 일부에 핸들러 코드 자체를 영구히 할당한다. 후자 방식을 **연결 변환** 이라 부른다.

### TLB의 구성

TLB는 **완전 연관(fully associative)** 방식으로 설계된다. 완전 연관 방식은 그냥 변환 정보가 TLB의 어떤 슬롯에도 저장될 수 있다는 것이다. 따라서 원하는 변환 정보를 찾을 때 TLB 전체에서 병렬적으로 검색이 수행된다. 

TLB는 “**VPN | PFN | 다른 비트”** 로 구성되어 있다. 이 때 Valid Bit, Protection Bit, ASID, Dirty Bit 등이 있는데 Valid Bit는 페이지 테이블의 Valid Bit와는 다르다. TLB에서는 그냥 해당 변환 정보가 캐싱되었으니 사용해도 좋다 정도의 의미이다.

### 문맥 교환

만약 프로세스간 문맥 교환이 발생하면 어떨까? 프로세스1의 실행 과정에서 TLB에 갱신된 변환 정보는 프로세스2에겐 아무 의미가 없다. **만약 P1의 VPN10이 PFN100에 대응되고 P2의 VPN10은 PFN170에 대응되면 어떤 변환 정보를 사용해야 되는 것일까? 프로세스의 VPN10은 어떤 주소로 변환될까?**

<img width="208" alt="image (1)" src="https://github.com/user-attachments/assets/49405445-8fdf-43de-99e6-a02df162fefd" />

이 문제를 해결하기 위해서는 2가지 방법이 있는데 첫 번째로는 문맥 교환이 발생할 때 기존 TLB 내용을 지우는 것이다. valid 값을 0으로 만드는 것이다. 그러나 이 방식은 비용이 발생하기 때문에 부담이 된다.

이 부담을 개선하기 위해 TLB에 **주소 공간 식별자(address space identifier, ASID)** 필드를 추가했다. ASID는 프로세스를 구분하기 위한 식별자이다. 

<img width="263" alt="image (2)" src="https://github.com/user-attachments/assets/1bad1637-4023-448f-b2ef-3cd727f70132" />

이렇게 ASID가 추가되면 프로세스 별로 TLB 변환 정보를 구별할 수 있다.

<img width="264" alt="image (3)" src="https://github.com/user-attachments/assets/1e0f56dc-8bd4-4008-ba76-2dcb4e0d8658" />

추가로 위와 같은 케이스도 있는데 이는 서로 다른 프로세스끼리 페이지를 공유하는 경우이다. 보통 코드 공유인 경우가 많은데 이렇게 페이지를 공유하면 메모리 부하를 줄일 수 있어 좋다.

### 교체 정책

모든 캐시가 그러하듯이 캐시 교체 정책이 매우 중요하다. 나중에 자세히 다루겠지만 보통은 **LRU** 정책을 많이 사용한다. 사용되지 않은지 가장 오래된 항목부터 교체한다. 랜덤 정책을 사용하기도 하는데 랜덤 정책도 나름 예외 상황 발생을 줄일 수 있다는 장점도 있다.

### 실제 TLB

<img width="452" alt="스크린샷 2025-04-20 오후 10 55 33" src="https://github.com/user-attachments/assets/f296830a-6172-4f9f-b2e7-b36933f72445" />

32비트 운영체제, 4KB 페이지라고 해보자. VPN은 20비트여야 하는데 왜 19비트일까? 보통 커널 영역과 사용자 영역은 주소공간의 절반씩 사용하기 때문이다. PFN에 24비트가 할당되어 있는 걸로 보아 물리 메모리의 크기는 64GB이다. 여기서 **G(Global)은 전역 비트** 이다. 이 비트는 프로세스 간에 공유되는 페이지들을 위해 사용된다. 이전에 언급한 ASID 필드도 있고 C는 Coherence, D는 Dirty, V는 Valid이다.

위의 그림은 MIPS의 TLB인데 일반적으로 32개 또는 64개 항목으로 구성되지만 일부는 운영체제를 위해 예약이 되어 있다. 앞서 언급한 것처럼 TLB Miss를 소프트웨어로 처리할 때 사용할 TLB 미스 핸들러 코드와 데이터를 저장하기도 한다.

추가로 예전 컴구 수업때 백교수님이 말씀해주셨던 것 같은데.. 이 책엔 자세히 나와있지는 않았다. 우리가 L1, L2 캐시를 사용할 때 사실 캐시에 key:value 형식을 보통 사용하는 것처럼 캐시에는 **Tag** 가 있다. 이 Tag는 보통 물리 메모리를 사용하기 때문에 캐시에 접근할 때는 물리 메모리 주소가 필요하다. 따라서 **캐시 접근 이전에 주소 변환이 이루어져야 한다.** 이 부분에서 성능 병목이 발생할 수 있다. 따라서 주소 변환 없이 **가상 주소로 캐시를 접근하는 방식** 들도 등장했는데 새로운 하드웨어 설계 문제들이 발생할 수 있다.

## 20. Advanced Page Tables

페이지 테이블을 모두 메모리에 적재하는 것은 부담이 된다고 했다. 그럼 페이지 테이블의 크기를 어떻게 줄일 수 있을까?

### 더 큰 페이지

페이지 크기를 늘리는 방법이 있다. 페이지 크기를 늘리게 되면 페이지 개수가 줄어들어 PTE 개수가 줄고, 자연스럽게 페이지 테이블의 크기가 줄어든다. 그러나 이 방식은 페이지 크기가 커지면서 내부 단편화 문제가 발생할 수 있고 오히려 메모리가 부족해진다.

### 하이브리드 방식

페이징과 세그멘테이션을 혼합한 하이브리드 방식도 많이 사용된다. 코드, 힙, 스택 세그먼트에 대해 페이지 테이블을 각각 두고, 각 세그먼트에 대해 베이스 레지스터와 바운드 레지스터를 둔다. 베이스 레지스터는 세그먼트의 페이지 테이블의 시작 주소를, 바운드 레지스터는 끝 주소를 저장한다. 이렇게 되면 힙과 스택 사이의 사용하지 않는 공간들이 페이지 테이블 상에서 공간을 차지하지 않게 된다.

그러나 이 방식도 여전히 문제가 있는데 세그멘테이션 자체가 세그먼트 별로 크기가 고정되어 있어 유연하지 못해 메모리 낭비가 발생한다. 또한 하이브리드 방식에선 페이지 테이블의 크기에 제한이 없기 때문에 페이지 테이블용 공간을 확보하는 것이 복잡하다.

### 멀티 레벨 페이지 테이블

세그멘테이션 없이 페이지 테이블의 크기를 줄이기 위한 방식이 바로 **멀티 레벨 페이지 테이블** 이다. 페이지 테이블을 페이지 크기의 단위로 나누고 페이지에 유효하지 않은 항목들만 있다면 해당 페이지는 할당하지 않는다. 페이지 디렉터리라는 자료구조를 사용해 페이지 테이블의 각 페이지의 할당 여부와 위치를 파악한다.

<img width="483" alt="image (4)" src="https://github.com/user-attachments/assets/83b5870a-5a03-4d3a-8c97-075f7698ed39" />

페이지 디렉터리의 각 항목은 페이지 테이블의 한 페이지를 나타낸다. 이 때 페이지 디렉터리의 Valid Bit는 그 항목이 가리키는 페이지의 PTE 중 적어도 하나의 PTE가 유효함을 의미한다. 이 방식은 우선 사용된 주소 공간의 크기에 비례하여 페이지 테이블 공간이 할당된다. 안 쓰는 공간에 대해서는 페이지 테이블을 할당하지 않기 때문이다. 또한 페이지 테이블을 페이지 크기로 분할하면서 메모리 관리가 용이하다. 선형 페이지 테이블은 연속된 물리 공간을 차지하지만 멀티 레벨 페이징에서는 각 페이지 테이블의 페이지들이 산재해 있을 수 있다.

그러나 TLB Miss 시, 메모리 접근이 2번 발생한다. 페이지 디렉터리에 1번, 페이지 테이블에 1번이다. 따라서 공간적인 여유가 생겼지만 메모리 접근 시간이 오히려 증가해버렸다. 또한 선형 페이지 테이블에 비해 페이지 테이블 검색 자체가 복잡하다.

2단계 이상의 멀티 레벨 페이징도 가능하다. 2단계에서의 페이지 디렉터리를 또 페이지 크기 단위로 나누고 새로운 페이지 디렉터리를 두면 된다. 

### 역 페이지 테이블

시스템에 단 하나의 페이지 테이블만 두는 획기적인 방법이다. 역 페이지 테이블의 각 항목은 해당 물리 페이지를 사용 중인 프로세스 번호와 가상 페이지 번호를 갖고 있다. 역 페이지 테이블에서는 주소 변환을 위해 전체 테이블을 검색해서 가상 주소 페이지와 매핑된 물리 프레임 번호를 찾아야 한다. 탐색 속도 향상을 위해 주로 해시 테이블을 사용한다.

### 스와핑

사실 페이지 테이블은 물리 메모리에만 존재하진 않는다. 커널 가상 메모리에 두거나 메모리가 부족하면 디스크로 스왑 아웃 시키기도 한다.
